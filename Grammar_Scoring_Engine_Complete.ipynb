{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar Scoring Engine for Spoken Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook develops a comprehensive solution for scoring the grammatical quality of spoken audio samples on a scale from 1 to 5. The objective is to build a model that takes audio files as input and outputs a continuous score based on the grammar quality of the speech.\n",
    "\n",
    "### Task Description\n",
    "- **Audio files**: 45-60 seconds long WAV files\n",
    "- **Labels**: MOS Likert Grammar Scores (1-5 scale)\n",
    "- **Training dataset**: 444 samples\n",
    "- **Testing dataset**: 195 samples\n",
    "- **Evaluation metric**: Pearson Correlation\n",
    "\n",
    "### Grammar Score Rubric\n",
    "- **1**: The person's speech struggles with proper sentence structure and syntax, displaying limited control over simple grammatical structures and memorized sentence patterns.\n",
    "- **2**: The person has a limited understanding of sentence structure and syntax. Although they use simple structures, they consistently make basic sentence structure and grammatical mistakes. They might leave sentences incomplete.\n",
    "- **3**: The person demonstrates a decent grasp of sentence structure but makes errors in grammatical structure, or they show a decent grasp of grammatical structure but make errors in sentence syntax and structure.\n",
    "- **4**: The person displays a strong understanding of sentence structure and syntax. They consistently show good control of grammar. While occasional errors may occur, they are generally minor and do not lead to misunderstandings; the person can correct most of them.\n",
    "- **5**: Overall, the person showcases high grammatical accuracy and adept control of complex grammar. They use grammar accurately and effectively, seldom making noticeable mistakes. Additionally, they handle complex language structures well and correct themselves when necessary.\n",
    "\n",
    "## Solution Approach\n",
    "\n",
    "Our solution approach consists of the following steps:\n",
    "\n",
    "1. **Data Exploration**: Understand the distribution of audio files and their labels\n",
    "2. **Feature Extraction**: Extract relevant features from audio files\n",
    "   - Audio features (MFCC, spectrograms, etc.)\n",
    "   - Prosodic features (tempo, rhythm, etc.)\n",
    "3. **Model Development**: Build and train different regression models\n",
    "4. **Model Evaluation**: Evaluate models using cross-validation and Pearson correlation\n",
    "5. **Model Tuning**: Fine-tune the best performing model\n",
    "6. **Prediction**: Generate predictions for the test set\n",
    "\n",
    "Let's begin by setting up our environment and exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Import our custom modules\n",
    "import feature_extraction\n",
    "import model_building\n",
    "import predict\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set paths\n",
    "DATA_PATH = 'dataset/'\n",
    "TRAIN_AUDIO_PATH = os.path.join(DATA_PATH, 'audios_train')\n",
    "TEST_AUDIO_PATH = os.path.join(DATA_PATH, 'audios_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "Let's start by loading the training and testing data and exploring their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load training and testing data\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Testing data shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "# Display sample of training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in training data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in testing data:\")\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Explore the distribution of labels in the training set\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(train_df['label'], bins=9, kde=True, color='darkblue')\n",
    "plt.title('Distribution of Grammar Scores in Training Data', fontsize=16)\n",
    "plt.xlabel('Grammar Score', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(np.arange(1, 5.5, 0.5))\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary statistics of grammar scores:\")\n",
    "print(train_df['label'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
