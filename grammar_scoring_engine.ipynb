{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar Scoring Engine for Spoken Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook develops a solution for scoring the grammatical quality of spoken audio samples on a scale from 1 to 5. The objective is to build a model that takes audio files as input and outputs a continuous score based on the grammar quality of the speech.\n",
    "\n",
    "### Task Description\n",
    "- Audio files are 45-60 seconds long WAV files\n",
    "- Labels are MOS Likert Grammar Scores (1-5 scale)\n",
    "- Training dataset: 444 samples\n",
    "- Testing dataset: 195 samples\n",
    "- Evaluation metric: Pearson Correlation\n",
    "\n",
    "### Grammar Score Rubric\n",
    "- **1**: Struggles with proper sentence structure and syntax\n",
    "- **2**: Limited understanding of sentence structure with basic mistakes\n",
    "- **3**: Decent grasp of structure but errors in grammar or syntax\n",
    "- **4**: Strong understanding with occasional minor errors\n",
    "- **5**: High grammatical accuracy with complex structures\n",
    "\n",
    "## Approach Overview\n",
    "\n",
    "Our approach will consist of the following steps:\n",
    "\n",
    "1. **Data Exploration**: Understand the distribution of audio files and labels\n",
    "2. **Feature Extraction**: Extract relevant features from audio files\n",
    "   - Audio features (MFCC, spectrograms, etc.)\n",
    "   - Speech transcription and text features\n",
    "3. **Model Development**: Build and train models to predict grammar scores\n",
    "4. **Evaluation**: Evaluate models using cross-validation and appropriate metrics\n",
    "5. **Testing**: Generate predictions for the test set\n",
    "\n",
    "Let's begin by setting up our environment and exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import librosa\n",
    "import librosa.display\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set paths\n",
    "DATA_PATH = 'dataset/'\n",
    "TRAIN_AUDIO_PATH = os.path.join(DATA_PATH, 'audios_train')\n",
    "TEST_AUDIO_PATH = os.path.join(DATA_PATH, 'audios_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "Let's start by loading the training and testing data and exploring their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load training and testing data\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Testing data shape: {test_df.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "\n",
    "# Display sample of training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Explore the distribution of labels in the training set\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['label'], bins=9, kde=True)\n",
    "plt.title('Distribution of Grammar Scores in Training Data')\n",
    "plt.xlabel('Grammar Score')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary statistics of grammar scores:\")\n",
    "print(train_df['label'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to load and display a sample audio file\n",
    "def load_and_display_audio(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Plot waveform\n",
    "    plt.subplot(1, 2, 1)\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title(f'Waveform (Duration: {duration:.2f}s)')\n",
    "    \n",
    "    # Plot spectrogram\n",
    "    plt.subplot(1, 2, 2)\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return y, sr, duration\n",
    "\n",
    "# Let's look at some examples from different score categories\n",
    "# First, sort the dataframe by label\n",
    "sorted_df = train_df.sort_values('label')\n",
    "\n",
    "# Sample from low, medium, and high scores\n",
    "low_score = sorted_df.iloc[0]['filename']\n",
    "medium_score = sorted_df.iloc[len(sorted_df)//2]['filename']\n",
    "high_score = sorted_df.iloc[-1]['filename']\n",
    "\n",
    "print(f\"Low score example: {low_score}, Score: {sorted_df.iloc[0]['label']}\")\n",
    "y_low, sr_low, dur_low = load_and_display_audio(os.path.join(TRAIN_AUDIO_PATH, low_score))\n",
    "\n",
    "print(f\"Medium score example: {medium_score}, Score: {sorted_df.iloc[len(sorted_df)//2]['label']}\")\n",
    "y_med, sr_med, dur_med = load_and_display_audio(os.path.join(TRAIN_AUDIO_PATH, medium_score))\n",
    "\n",
    "print(f\"High score example: {high_score}, Score: {sorted_df.iloc[-1]['label']}\")\n",
    "y_high, sr_high, dur_high = load_and_display_audio(os.path.join(TRAIN_AUDIO_PATH, high_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
